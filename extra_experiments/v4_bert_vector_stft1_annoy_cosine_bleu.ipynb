{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.translate import bleu_score\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "df = pd.read_csv(\"./data/comment_finder/all.csv\")\n",
    "\n",
    "chencherry = bleu_score.SmoothingFunction()\n",
    "\n",
    "def getBleuScore(test_idx, match_idx):\n",
    "    ref = df.iloc[[test_idx]].to_records()[0][2]\n",
    "    hyp = df.iloc[[match_idx]].to_records()[0][2]\n",
    "    bleu_score_val = bleu_score.sentence_bleu([ref], hyp, smoothing_function=chencherry.method1)\n",
    "    return bleu_score_val\n",
    "\n",
    "\n",
    "def find_similiar(data_vector, test_id):\n",
    "\n",
    "    A = data_vector[test_id]\n",
    "\n",
    "    max_cosine = 0\n",
    "    max_sim_id=-1\n",
    "    for i, B in enumerate(data_vector):\n",
    "        cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "        if i == test_id:\n",
    "            continue\n",
    "        if cosine>max_cosine:\n",
    "            max_sim_id = i\n",
    "            max_cosine = cosine\n",
    "    return max_sim_id, max_cosine\n",
    "\n",
    "def array_to_image(array):\n",
    "    array = np.clip(array, 0, 255).astype(np.uint8)\n",
    "    return Image.fromarray(array.reshape(-1, array.shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model(microsoft/unixcoder-base)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150677/150677 [01:55<00:00, 1300.86it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9643328, 64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(150677, 4096)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from libs.feature_extraction.vectorizers import BertVectorizer\n",
    "import numpy as np\n",
    "from scipy.signal import stft\n",
    "import tensorflow as tf\n",
    "\n",
    "bert = BertVectorizer(\"microsoft/unixcoder-base\")\n",
    "vectors = bert.load_vectors(\"data/comment_finder/vectors/bert_vectors.npy\")\n",
    "\n",
    "stft_list=[]\n",
    "\n",
    "for index, vector in tqdm(enumerate(vectors), total=len(vectors)):\n",
    "    f, t, Zxx_db = stft(vector, fs = 128, nperseg = 128, noverlap = 116, nfft = 128)\n",
    "    Zxx_db = tf.abs(Zxx_db)\n",
    "    Zxx_db = Zxx_db[:64,:64]\n",
    "    stft_list.append(Zxx_db)\n",
    "    \n",
    "stft_list = np.concatenate(stft_list)\n",
    "display(stft_list.shape)\n",
    "vectors = stft_list.reshape(stft_list.shape[0]//64, 4096)\n",
    "display(vectors.shape)\n",
    "np.save(\"v4_vectors\", vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150677/150677 [01:27<00:00, 1724.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from annoy import AnnoyIndex\n",
    "\n",
    "dims = 4096\n",
    "trees = 10000\n",
    "file_index_to_file_vector = {}\n",
    "\n",
    "# build ann index\n",
    "t = AnnoyIndex(dims, metric='angular')\n",
    "for i in tqdm(range(vectors.shape[0])):\n",
    "    file_vector = vectors[i].reshape(dims,1)\n",
    "    file_index_to_file_vector[i] = file_vector\n",
    "    t.add_item(i, file_vector)\n",
    "t.build(trees)\n",
    "t.save(\"v4.annoy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from annoy import AnnoyIndex\n",
    "\n",
    "dims = 4096\n",
    "trees = 10000\n",
    "file_index_to_file_vector = {}\n",
    "\n",
    "# build ann index\n",
    "t = AnnoyIndex(dims, metric='angular')\n",
    "t.load(\"v4.annoy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 285/30136 [00:16<29:28, 16.88it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39m>\u001b[39m toplam\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[1;32m     12\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m nearest_neighbours \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mget_nns_by_vector(vectors[test_idx], \u001b[39m2\u001b[39;49m)\n\u001b[1;32m     14\u001b[0m max_sim_id \u001b[39m=\u001b[39m nearest_neighbours[\u001b[39m1\u001b[39m]\n\u001b[1;32m     15\u001b[0m bleu_score_val \u001b[39m=\u001b[39m getBleuScore(test_idx,max_sim_id)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "test_df = pd.read_csv(\"./results/bert_cosine_bleu_C1_F5/fold_1.csv\")\n",
    "vectors = np.load(\"v4_vectors.npy\")\n",
    "test_series = test_df.test_idx\n",
    "\n",
    "sum = 0\n",
    "toplam = len(test_series)\n",
    "for index, test_idx in tqdm(enumerate(test_series), total=toplam):\n",
    "    if index > toplam-1:\n",
    "        break\n",
    "    nearest_neighbours = t.get_nns_by_vector(vectors[test_idx], 2)\n",
    "    max_sim_id = nearest_neighbours[1]\n",
    "    bleu_score_val = getBleuScore(test_idx,max_sim_id)\n",
    "    sum = sum + bleu_score_val\n",
    "    \n",
    "avg_bleu_score = sum / toplam\n",
    "display(avg_bleu_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bleu Score: 0.13091595869126196: 100%|██████████| 150677/150677 [2:58:26<00:00, 14.07it/s]  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.13091595869126196"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "test_df = pd.read_csv(\"./results/bert_cosine_bleu_C1_F5/fold_1.csv\")\n",
    "vectors = np.load(\"v4_vectors.npy\")\n",
    "\n",
    "sum = 0\n",
    "tq = tqdm(range(len(vectors)))\n",
    "for index in tq:\n",
    "    nearest_neighbours = t.get_nns_by_vector(vectors[index], 2)\n",
    "    max_sim_id = nearest_neighbours[1]\n",
    "    bleu_score_val = getBleuScore(index,max_sim_id)\n",
    "    sum = sum + bleu_score_val\n",
    "    tq.set_description(\"Bleu Score: %s\" % str(sum / (index+1)))\n",
    "        \n",
    "    \n",
    "avg_bleu_score = sum / len(vectors)\n",
    "display(avg_bleu_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yk_code_review",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "112ce86275c94deb821632ef6827abb5d945ed622abd934339e6f746d4034028"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
