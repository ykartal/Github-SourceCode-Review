{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from libs.feature_extraction.vectorizers import TfIdfVectorizer, BowVectorizer, BertVectorizer, Doc2VecVectorizer, Word2VecMeanVectorizer\n",
    "import numpy as np\n",
    "import json\n",
    "import javalang\n",
    "from scipy.signal import stft\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths = json.loads(open('embedding_paths.json').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model(microsoft/unixcoder-base)...\n"
     ]
    }
   ],
   "source": [
    "# tf_idf = TfIdfVectorizer(\"./model/tfidf_vectorizer.pkl\")\n",
    "# bow = BowVectorizer(\"./model/tfidf_vectorizer.pkl\")\n",
    "# d2v = Doc2VecVectorizer(\"./model/d2v/d2v.model\")\n",
    "# w2v = Word2VecMeanVectorizer(\"./model/w2v/w2v.model\")\n",
    "bert = BertVectorizer(\"microsoft/unixcoder-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"System.out.println(\\\"Hello World!\\\")\"\n",
    "# tokens = [token.value for token in javalang.tokenizer.tokenize(code)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 499.86it/s]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/it]\n"
     ]
    }
   ],
   "source": [
    "# tf_idf_vec = tf_idf.transform([code])\n",
    "# bow_vec = bow.transform([code])\n",
    "# d2v_vec = d2v.transform([tokens])\n",
    "# w2v_vec = w2v.transform([tokens])\n",
    "bert_vec = bert.transform([code])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(\"tf_idf_vec.txt\", tf_idf_vec.toarray())\n",
    "# np.savetxt(\"bow_vec.txt\", bow_vec.toarray())\n",
    "# np.savetxt(\"d2v_vec.txt\", d2v_vec)\n",
    "# np.savetxt(\"w2v_vec.txt\", w2v_vec)\n",
    "# np.savetxt(\"bert_vec.txt\", bert_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_image(array):\n",
    "    array = np.clip(array, 0, 255).astype(np.uint8)\n",
    "    return Image.fromarray(array.reshape(-1, array.shape[-1]))\n",
    "\n",
    "f, t, Zxx = stft(bert_vec)\n",
    "\n",
    "Zxx_db = 20 * np.log10(np.abs(Zxx))\n",
    "Zxx_db -= Zxx_db.min()\n",
    "Zxx_db /= Zxx_db.max()\n",
    "Zxx_db = (Zxx_db * 255).astype(np.uint8)\n",
    "\n",
    "image = array_to_image(Zxx_db)\n",
    "image.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f8cf77c51bdd57ba638a1c8caf3e4c5611a3b47850360d5dea5b65d02fac5505"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
